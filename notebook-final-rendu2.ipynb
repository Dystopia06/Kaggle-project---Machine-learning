{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6674905,"sourceType":"datasetVersion","datasetId":1936563}],"dockerImageVersionId":30619,"isInternetEnabled":true,"language":"r","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Kaggle Project**\n\n# \"Personal Key Indicators of Heart Disease\"\n\n---\n\n\n- Cormet Dylan\n- Lheureux Dylan\n- Batard Robin\n- Choiset Flore\n\n---\n\n**Quels sont les facteurs pouvant provoquer des attaques cardiaques ?**","metadata":{}},{"cell_type":"markdown","source":"## Première partie (rendu 1) : Analyse globale du dataset","metadata":{}},{"cell_type":"code","source":"#Importation librairies\nlibrary(tidyverse) \nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(caTools)\nlibrary(caret)\nlibrary(forestmodel)\nlibrary(dplyr)\nlibrary(broom)\nlibrary(ggeffects)\nlibrary(yardstick)\nlibrary(rpart)\nlibrary(party)\nlibrary(randomForest)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:22:19.297307Z","iopub.execute_input":"2024-04-04T16:22:19.299986Z","iopub.status.idle":"2024-04-04T16:22:19.357739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dans cette première partie nous allons tout d'abord améliorer le format du dataset. C'est à dire  transformer les strings en int.  Nous avons aussi créé deux nouvelles colonnes \"AgeInf\" et \"AgeSup\" à partir de la colonne AgeCategory qui définissait un intervalle à partir d'un string. ","metadata":{}},{"cell_type":"code","source":"list.files(path = \"../input\")\n#importation dataset\ndata <- read.csv(\"../input/personal-key-indicators-of-heart-disease/2022/heart_2022_with_nans.csv\")\n#sélection des colonnes\ndata <- subset(data, select = -c(State, HadAngina, HadCOPD, HadDepressiveDisorder, HadKidneyDisease, HadArthritis, DeafOrHardOfHearing, BlindOrVisionDifficulty, DifficultyConcentrating, DifficultyDressingBathing, DifficultyErrands, ChestScan, HighRiskLastYear, CovidPos, PhysicalHealthDays, MentalHealthDays, ECigaretteUsage, HIVTesting, FluVaxLast12, PneumoVaxEver, TetanusLast10Tdap, HeightInMeters, WeightInKilograms, LastCheckupTime, RemovedTeeth))\n#On enleve les NA\ndata <- na.omit(data)\nfor (i in 1:length(data)){\ndata <- subset(data, data[i] !=\"\")\n    }\nsummary(data)\n#On transforme les colonnes Yes/No en 1/0\nconvert_Yes_No <- function(column) {\n  ifelse(column == \"No\", 0, ifelse(column == \"Yes\", 1, column))\n}\n\n# Appliquer la fonction à toutes les colonnes spécifiées\ncolumns_to_convert <- c(\"PhysicalActivities\", \"HadHeartAttack\",\n                        \"HadStroke\", \"HadAsthma\", \"HadSkinCancer\", \n                        \"HadDiabetes\", \"AlcoholDrinkers\", \"DifficultyWalking\")\n\n#On transforme \"Male\" en 0 et \"Female\" en 1 dans la colonne Sex\ndata[columns_to_convert] <- lapply(data[columns_to_convert], convert_Yes_No)\ndata$Sex <- ifelse(data$Sex == \"Male\", 0, \n                    ifelse(data$Sex == \"Female\", 1, data$Sex)) \ndata$HadDiabetes[data$HadDiabetes == 'No, pre-diabetes or borderline diabetes'] <- 0\ndata$HadDiabetes[data$HadDiabetes == 'Yes, but only during pregnancy (female)'] <- 0","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:22:19.362685Z","iopub.execute_input":"2024-04-04T16:22:19.366413Z","iopub.status.idle":"2024-04-04T16:22:32.383867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On affiche un résumé de notre dataset, on observe que l'on a 346165 lignes pour chaque variable. ","metadata":{}},{"cell_type":"code","source":"# Création d'un vecteur avec les valeurs uniques de la colonne GeneralHealth\nvaleurs_uniques <- c(\"Poor\",\"Fair\",\"Good\",\"Very good\",\"Excellent\")\n\n# Création d'une correspondance entre les valeurs uniques et les chiffres\ncorrespondance <- setNames(1:length(valeurs_uniques), valeurs_uniques)\n\n# Remplacement des valeurs de la colonne par les chiffres correspondants\ndata$GeneralHealth_numerique <- correspondance[data$GeneralHealth]\nvaleurs_uniques\n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:22:32.386817Z","iopub.execute_input":"2024-04-04T16:22:32.388423Z","iopub.status.idle":"2024-04-04T16:22:32.425946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#On transforme la colonne représentant les intervalles d'âges, trop dure à utiliser telle quelle\n# Fonction pour extraire le premier nombre\nextraire_premier_nombre <- function(phrase) {\n  nombre <- as.numeric(sub(\"^Age (\\\\d+).*\", \"\\\\1\", phrase))\n  if (is.na(nombre)) {\n    nombre <- NA\n  }\n  return(nombre)\n}\n\n\n# Fonction pour extraire le deuxième nombre\nextraire_deuxieme_nombre <- function(phrase) {\n  if (grepl(\"80 or older\", phrase)) {\n    nombre <- \"100\"\n  } else {\n    nombre <- gsub(\"^Age \\\\d+ to (\\\\d+)\", \"\\\\1\", phrase)\n  }\n  return(nombre)\n}\n\ndata$AgeInf <- sapply(data$AgeCategory, extraire_premier_nombre)\ndata$AgeSup <- sapply(data$AgeCategory, extraire_deuxieme_nombre)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:22:32.428951Z","iopub.execute_input":"2024-04-04T16:22:32.430516Z","iopub.status.idle":"2024-04-04T16:22:48.096678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Pour la colonne des fumeurs on simplifie en \"A deja fumé\" : 1 et \"n'a jamais fumé\" : 0\n# Parcours de la colonne et remplacement des valeurs\ndata$SmokerStatus <- ifelse(data$SmokerStatus == \"Never smoked\", 0, 1)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:22:48.100407Z","iopub.execute_input":"2024-04-04T16:22:48.101928Z","iopub.status.idle":"2024-04-04T16:22:48.130510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head(data)\n# Conversion de toutes les colonnes qui avaient des Strings : \n#SmokerStatus : 0 si n'a jamais fumé et 1 si a déjà fumé\n# Sex : 0 si homme 1 si femme\n# GeneralHealth -> ajout de GeneralHealth_numerique : 1 si excellent, 2 si very good, 4 poor et 5 good\n#AgeCategory : Creation de AgeInf et Agesup avec Ageinf la borne inf de l'intervalle \n# ex : AgeInf vaut 65 pour \"Age 65 to 69\" et AgeSup vaut 69. Si on a \"80 or older\" AgeSup vaut 100\n# Pour toute autre colonne avec Yes/No : No vaut  0 et Yes vaut 1 ","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:22:48.135346Z","iopub.execute_input":"2024-04-04T16:22:48.137084Z","iopub.status.idle":"2024-04-04T16:22:48.176894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On affiche les premiers éléments de notre dataset pour vérifier que l'on a bien réussi à créer nos nouvelles variables. ","metadata":{}},{"cell_type":"code","source":"mean(data$HadHeartAttack ==1)*100","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:22:48.179820Z","iopub.execute_input":"2024-04-04T16:22:48.181390Z","iopub.status.idle":"2024-04-04T16:22:48.207044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On a d'abord calculé la probabilité moyenne de faire une attaque cardiaque ( de manière globale ). Cette probabilité est de 5.65%. On pourra par la suite s'en servir de référence afin de comparer si telle ou telle variable possède une influence sur le risque de faire une attaque cardiaque. ","metadata":{}},{"cell_type":"code","source":"#Création du graphique représentant la Probabilité de faire une attaque cardiaque sachant qu'on est malade\n# Calcul des proportions\nproportions <- c(\n  sum(data$HadHeartAttack == 1 & data$HadStroke == 1) / sum(data$HadStroke == 1) * 100,\n  sum(data$HadHeartAttack == 1 & data$HadAsthma == 1) / sum(data$HadAsthma == 1) * 100,\n  sum(data$HadHeartAttack == 1 & data$HadSkinCancer == 1) / sum(data$HadSkinCancer == 1) * 100,\n  sum(data$HadHeartAttack == 1 & data$HadDiabetes == 1) / sum(data$HadDiabetes == 1) * 100,\n  sum(data$HadHeartAttack == 1 & data$HadDiabetes == 0 & data$HadStroke == 0 & data$HadAsthma == 0 & data$HadSkinCancer == 0) / sum(data$HadDiabetes == 0 & data$HadStroke == 0 & data$HadAsthma == 0 & data$HadSkinCancer == 0) * 100\n)\n\n# Noms des variables\nnames <- c(\"Stroke\", \"Asthma\", \"Skin Cancer\", \"Diabetes\",\"No disease\")\n\n# Création de l'histogramme\nbarplot(proportions, \n        names.arg = names, \n        xlab = \"Maladie\", \n        ylab = \"Pourcentage\",\n        main = \"Probabilité de faire une attaque cardiaque sachant qu'on est malade\",\n        ylim = c(0, max(proportions) * 1.2))  # Échelonnage de l'axe des y\n\n# Ajout des pourcentages sur les barres\ntext(x = 1:length(proportions), \n     y = proportions, \n     labels = paste(round(proportions, 2), \"%\"), \n     pos = 3, \n     cex = 0.8, \n     col = \"blue\")\n\npng(\"pourcentage_maladies.png\", width = 800, height = 600)\ndev.off()","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:22:48.209826Z","iopub.execute_input":"2024-04-04T16:22:48.211350Z","iopub.status.idle":"2024-04-04T16:22:48.613090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On a d'abord calculé la probabilité moyenne de faire une attaque cardiaque ( de manière globale ). Cette probabilité est de 5.65%. On pourra par la suite s'en servir de référence afin de comparer si telle ou telle variable possède une influence sur le risque de faire une attaque cardiaque. ","metadata":{}},{"cell_type":"code","source":"#Création du graphique représentant la Distribution des heures de sommeil : s'il y a eu une attaque cardiaque ou non\n# Séparer les données en deux sous-ensembles pour chaque valeur de HadHeartAttack\ndata_heart_attack_0 <- data[data$HadHeartAttack == 0, ]\ndata_heart_attack_1 <- data[data$HadHeartAttack == 1, ]\n\n\n\n# Créer un graphique avec superposition de PMF pour chaque groupe, en normalisant les fréquences\nggplot() +\n  geom_bar(data = data_heart_attack_1, aes(x = SleepHours, y = after_stat(count/sum(count)), fill = \"A eu une attaque cardiaque\"), alpha = 0.5, position = \"identity\") +\n  geom_bar(data = data_heart_attack_0, aes(x = SleepHours, y = after_stat(count/sum(count)), fill = \"N'a pas eu d'attaque cardiaque\"), alpha = 0.5, position = \"identity\") +\n  labs(x = \"Heures de sommeil\", y = \"Fréquence\", fill = \"Group\") +\n  ggtitle(\"Distribution des heures de sommeil : s'il y a eu une attaque cardiaque ou non\") +\n  scale_fill_manual(values = c(\"A eu une attaque cardiaque\" = \"red\", \"N'a pas eu d'attaque cardiaque\" = \"blue\"),\n                     labels = c(\"A eu une attaque cardiaque\", \"N'a pas eu d'attaque cardiaque\")) +\n  theme_minimal() +\n  xlim(0, 15)  # Fixer la limite de l'axe des x à 15\n\n# Sauvegarder le graphique\npng(\"distribution-sommeil.png\", width = 800, height = 600)\ndev.off()\n\n# Le warning est normal : on a cut l'abscisse x aux valeurs > 15","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:22:48.617742Z","iopub.execute_input":"2024-04-04T16:22:48.619321Z","iopub.status.idle":"2024-04-04T16:22:50.066928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sur ce second graphique, on s'intéresse à la probabilité de faire une attaque cardiaque selon le nombre d'heures de sommeil. On observe qu'il y a un peu plus de personnes dormant plus de 7h ou moins de 6h parmi celles ayant fait une attaque cardiaque que parmi celles n'en ayant pas fait. Les heures de sommeil et la probabilité de faire une attaque cardiaque semblent donc être corrélés. ","metadata":{}},{"cell_type":"code","source":"#Création du graphique représentant la Répartition des catégories d'IMC chez les personnes ayant eu une attaque cardiaque\n# Calcul des pourcentages pour chaque catégorie de BMI\nSouspoids <- sum(data$BMI < 18.5 & data$HadHeartAttack == 1) / sum(data$BMI < 18.5) * 100\nNormal <- sum(data$BMI >= 18.5 & data$BMI < 25 & data$HadHeartAttack == 1) / sum(data$BMI >= 18.5 & data$BMI < 25) * 100\nSurpoids <- sum(data$BMI >= 25 & data$BMI < 30 & data$HadHeartAttack == 1) / sum(data$BMI >= 25 & data$BMI < 30) * 100\nObese <- sum(data$BMI >=30 & data$HadHeartAttack == 1) / sum(data$BMI >=30) * 100\n\n# Création des étiquettes pour les portions de camembert avec pourcentage\nlabels <- paste(c(\"Souspoids\", \"Normal\", \"Surpoids\", \"Obèse\"), \" (\", round(c(Souspoids, Normal, Surpoids, Obese), 1), \"%)\", sep = \"\")\n\n# Création du diagramme en camembert\npie(c(Souspoids, Normal, Surpoids, Obese), labels = labels, main = \"Répartition des catégories d'IMC\\nchez les personnes ayant eu une attaque cardiaque\")\n\npng(\"IMC.png\", width = 800, height = 600)\ndev.off()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:22:50.071408Z","iopub.execute_input":"2024-04-04T16:22:50.073765Z","iopub.status.idle":"2024-04-04T16:22:50.342590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ici, on s'intéresse à l'IMC des personnes qui ont fait une attaque cardiaque. Il faut savoir que l'étude a été faite aux Etats-Unis, où l'IMC moyen est de 28,5 (Surpoids). On observe une légère relation entre l'IMC et la probabilité de faire une attaque cardiaque. En effet, être en surpoids ou obèse fait passer la probabilité au dessus de la moyenne calculée. Etre de corpulence normale en revanche, réduit ce risque. Néanmoins, on observe que l'influence n'est pas si élevée que ça. ","metadata":{}},{"cell_type":"code","source":"#Création du graphique représentant la Probabilité de faire une attaque cardiaque sachant un état de santé donné\np1 <- sum(data$GeneralHealth_numerique == 1 & data$HadHeartAttack == 1) / sum(data$GeneralHealth_numerique == 1) * 100\np2 <- sum(data$GeneralHealth_numerique == 2 & data$HadHeartAttack == 1) / sum(data$GeneralHealth_numerique == 2) * 100\np3 <- sum(data$GeneralHealth_numerique == 3 & data$HadHeartAttack == 1) / sum(data$GeneralHealth_numerique == 3) * 100\np4 <- sum(data$GeneralHealth_numerique == 4 & data$HadHeartAttack == 1) / sum(data$GeneralHealth_numerique == 4) * 100\np5 <- sum(data$GeneralHealth_numerique == 5 & data$HadHeartAttack == 1) / sum(data$GeneralHealth_numerique == 5) * 100\n\n\n\n# Créer un dataframe avec les données\nhealth_data <- data.frame(\n  Niveau_Sante = factor(1:5, labels = c(\"Poor\", \"Fair\", \"Good\", \"Very good\", \"Excellent\")),\n  Probabilite_CC = c(p1, p2, p3, p4, p5),\n  Pourcentage = c(p1, p2, p3, p4, p5)\n)\n\n# Créer le graphique\nggplot(health_data, aes(x = Niveau_Sante, y = Probabilite_CC, label = paste0(round(Pourcentage), \"%\"))) +\n  geom_line(aes(group = 1), color = \"blue\") +\n  geom_point(color = \"blue\", size = 3) +\n  geom_text(vjust = -0.5, color = \"black\") +\n  labs(x = \"Niveau de santé général\", y = \"Probabilité d'attaque cardiaque (%)\") +\n  ggtitle(\"Probabilité de faire une attaque cardiaque sachant un état de santé donné\") +\n  theme_minimal()\n\n\npng(\"Etat.png\", width = 800, height = 600)\ndev.off()","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:22:50.347182Z","iopub.execute_input":"2024-04-04T16:22:50.349915Z","iopub.status.idle":"2024-04-04T16:22:50.826704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sur ce graphique, On observe que plus l'état de santé général de la santé de la personne décroît, plus la probabilité de faire une attaque cardiaque est élevée. On atteint jusqu'à 22% pour une personne d'un état de santé \"Poor\" ce qui est environ 4 fois plus élevé que la moyenne ! Au contraire, avoir un état de santé excellent permet de diviser ce risque par 4. ","metadata":{}},{"cell_type":"code","source":"data$AgeInf <- as.integer(data$AgeInf)\n#Création du graphique représentant la Probabilité de faire une attaque cardiaque en fonction de l'âge et du sexe de la personne\ndifferent_age_inf <- unique(data$AgeInf)\ndifferent_age_inf <- sort(different_age_inf, decreasing = FALSE)\nn1 <- length(different_age_inf)\nnombre_hommes_par_categorie_1 <- numeric(length = n1)\nnombre_femmes_par_categorie_1 <- numeric(length = n1)\nnombre_hommes_par_categorie_malade_1 <- numeric(length = n1)\nnombre_femmes_par_categorie_malade_1 <- numeric(length = n1)\nproba_hommes_par_categorie_malade_1 <- numeric(length = n1)\nproba_femmes_par_categorie_malade_1 <- numeric(length = n1)\n\nfor (i in 1:n1) {\n  nombre_hommes_par_categorie_1[i] <- sum((data$Sex == 0) & (data$AgeInf == different_age_inf[i]))\n  nombre_femmes_par_categorie_1[i] <- sum((data$Sex == 1) & (data$AgeInf == different_age_inf[i]))\n  nombre_hommes_par_categorie_malade_1[i] <- sum((data$Sex == 0) & (data$AgeInf == different_age_inf[i]) & data$HadHeartAttack == 1)\n  nombre_femmes_par_categorie_malade_1[i] <- sum((data$Sex == 1) & (data$AgeInf == different_age_inf[i]) & data$HadHeartAttack == 1)\n  proba_hommes_par_categorie_malade_1[i] <- (nombre_hommes_par_categorie_malade_1[i] / nombre_hommes_par_categorie_1[i]) * 100\n  proba_femmes_par_categorie_malade_1[i] <- (nombre_femmes_par_categorie_malade_1[i] / nombre_femmes_par_categorie_1[i]) * 100\n}\n\ndata_table <- data.frame(\n  x = different_age_inf,\n  y = proba_hommes_par_categorie_malade_1,\n  z = proba_femmes_par_categorie_malade_1\n)\n\n# Créer un graphique avec une légende\nggplot() +\n  geom_line(data = data_table, aes(y = y, x = x, color = \"Homme\"), linetype = \"solid\", linewidth = 1) +\n  geom_line(data = data_table, aes(y = z, x = x, color = \"Femme\"), linetype = \"solid\", linewidth = 1) +\n  scale_color_manual(name = \"Sexe\", values = c(\"Homme\" = \"blue\", \"Femme\" = \"red\")) +\n  labs(title = \"Probabilité de faire une attaque cardiaque en fonction de l'âge et du sexe de la personne\", x = \"Age (en années)\", y = \"Risque (en %)\") +\n  theme_minimal()\n\npng(\"Vie.png\",width=800,height=600)\ndev.off()","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:22:50.831287Z","iopub.execute_input":"2024-04-04T16:22:50.832992Z","iopub.status.idle":"2024-04-04T16:22:52.262098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ici, on compare les deux indices les plus élémentaires : l'âge de la personne et son sexe. On observe assez logiquement que le risque augmente en fonction de l'âge et qu'une femme a moins de risque de faire une attaque cardiaque qu'un homme. A 80 ans, ce risque est de 20% et deux fois moins pour une femme, on observe bien cette corrélation. ","metadata":{}},{"cell_type":"markdown","source":"## Deuxième partie (rendu 2) : Analyse plus technique","metadata":{}},{"cell_type":"code","source":"# On retire les variables qui ne sont plus utiles : on décide d'éliminer RaceEthnicityCategory \n#Les trois autres variables sont remplacées par AgeInf et GeneralHealth_numerique\ndata <- subset(data, select = -c(AgeSup,GeneralHealth,RaceEthnicityCategory,AgeCategory))","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:22:52.266523Z","iopub.execute_input":"2024-04-04T16:22:52.268038Z","iopub.status.idle":"2024-04-04T16:22:52.356839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Il faut changer les types de nos variables car elles sont pour la plupart des chr et on veut des int/dbl.","metadata":{}},{"cell_type":"code","source":"#Changement de types\nfor (col in names(data)) {\n  if (col != \"BMI\") {\n    data[[col]] <- as.integer(data[[col]])\n  } else {\n    data[[col]] <- as.double(data[[col]])\n  }\n} \nhead(data)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:22:52.361230Z","iopub.execute_input":"2024-04-04T16:22:52.362959Z","iopub.status.idle":"2024-04-04T16:22:52.919935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Régression logistique**\n\nNous avons décidé de commencer l'analyse du dataset par une régression logistique car la plupart de nos variables sont binaires. Cela nous permet de faire une prédiction de la probabilité de faire une attaque cardiaque en fonction de toutes les autres variables et d'étudier l'influence des variables sur cette probabilité. ","metadata":{}},{"cell_type":"markdown","source":"On vérifie que les types sont corrects. ","metadata":{}},{"cell_type":"code","source":"#Creation d'espace d'entrainement et de test\n set.seed(123)\n train_index <- sample(nrow(data), floor(0.8*nrow(data)), replace = FALSE)\n train_data <- data[train_index, ]\n test_data <- data[-train_index, ]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:22:52.924044Z","iopub.execute_input":"2024-04-04T16:22:52.925558Z","iopub.status.idle":"2024-04-04T16:22:53.045091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Création du modèle de régression logistique\n#On entraine notre modèle avec les données du subdataset d'entrainement\nmodel <- glm(HadHeartAttack ~ ., data = train_data, family = binomial)\nsummary(model)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:22:53.049267Z","iopub.execute_input":"2024-04-04T16:22:53.050817Z","iopub.status.idle":"2024-04-04T16:22:55.268768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Par la suite, on s'intéressera aux coefficients (estimate) et aux p-values (Pr(>|z|) afin de comparer l'influence des variables et leurs pertinences.","metadata":{}},{"cell_type":"markdown","source":"Pour déterminer l'impact d'une variable dans un modèle on peut calculer son odds ratio et étudier sa position:\n- Si odds ratio<1 :  agit avec une tendance à la diminution\n- Si odds ratio > 1: agit avec une tendance à l'augmentation\n- Si odds ratio=1: action limité","metadata":{}},{"cell_type":"code","source":"odds_ratio<-exp(cbind(coef(model), confint(model)))\nodds_ratio\n# Affiche les odds ratio et leurs intervalls de confiance respectif pour chaque paramètre du modèle\n# Attention un peu long à afficher, mettre en commentaire ou en markdown si vous êtes pressé","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:22:55.273000Z","iopub.execute_input":"2024-04-04T16:22:55.274597Z","iopub.status.idle":"2024-04-04T16:24:27.573300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On peut tirer de ce tableau quelques enseignments :\n-  HadStroke,HadDiabetes,SmokersStatus,DifficultyWalking augmente le plus le risque en augmentant\n- Au contraire Sex, GénéralHealth_numérique et AlcoholDrinkers( chelou celui la ) semblent diminuer le risque lorsqu'ils augmentent","metadata":{}},{"cell_type":"code","source":"#Le modèle entraîné  prédit maintenant les valeurs d'HadHeartAttack de notre espace de test\n# On le compare aux vraies valeurs du subdataset de test\ny_pred <- predict(model, newdata = test_data, type = \"response\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:24:27.578724Z","iopub.execute_input":"2024-04-04T16:24:27.582402Z","iopub.status.idle":"2024-04-04T16:24:27.636060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot Predicted data and original data points\nggplot(test_data, aes(x = y_pred, y = test_data$HadHeartAttack)) +\n  geom_point() +\n  geom_smooth(method = \"glm\", aes(y = test_data$HadHeartAttack), method.args = list(family = \"binomial\"), color = \"green\", se = FALSE) +\n  labs(x = \"Predicted Probability\", y = \"HadHeartAttack\")","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:24:27.641627Z","iopub.execute_input":"2024-04-04T16:24:27.645403Z","iopub.status.idle":"2024-04-04T16:24:31.630639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ce premier graphique représente les valeurs de HadHeartAttack en fonction de leur probabilité calculée ( la valeur prédite ). On observe que plus la probabilité prédite est élevée, plus l'on se rapproche de la valeur 1 pour HadHeartAttack ce qui est logique : plus la probabilité est élevé, plus l'on a de chances de faire une attaque cardiaque. ","metadata":{}},{"cell_type":"code","source":"# Créer une fonction pour calculer la GBE\ncalculate_GDE <- function(threshold,prediction,test_data) {\n  # Convertir les prédictions en classes binaires en utilisant le seuil\n  predicted <- ifelse(prediction > threshold, 1, 0)\n  if (sum(predicted)== 0 ){\n     return (1.0)  \n   }\n  # Créer la matrice de confusion\n  confusion_matrix <- table(Predicted = predicted, Actual = test_data$HadHeartAttack)\n  \n  # Calculer les valeurs FP et FN\n  FP <- confusion_matrix[2, 1]\n  FN <- confusion_matrix[1, 2]\n  \n  # Calculer le nombre total d'observations\n  total_observations <- sum(confusion_matrix)\n  \n  # Calculer la GBE\n  GDE <- (FP + FN) / total_observations\n  \n  return(GDE)\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:24:31.635075Z","iopub.execute_input":"2024-04-04T16:24:31.636637Z","iopub.status.idle":"2024-04-04T16:24:31.652947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On crée une fonction qui calcule la GBE et permets de trouver le seuil optimal, c'est à dire l'endroit où on doit découper la probabilité en deux pour se ramener aux valeurs 0 ( pas de heart attack ) et 1 ( heart attack )","metadata":{}},{"cell_type":"code","source":"thresholds <- seq(0.1, 1, by = 0.01)  # Tester différents seuils de 0 à 1 avec un pas de 0.01\nGBEs <- sapply(thresholds, function(threshold) calculate_GDE(threshold,y_pred,test_data))\n\noptimal_threshold <- thresholds[which.min(GBEs)]\nmin_GDE <- min(GBEs)\n\n ##Afficher le seuil optimal et la GBE minimale\ncat(\"Seuil optimal :\", optimal_threshold, \"\\n\")\ncat(\"GBE minimale :\", min_GDE, \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:24:31.657065Z","iopub.execute_input":"2024-04-04T16:24:31.658630Z","iopub.status.idle":"2024-04-04T16:24:35.897552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Le modèle entraîner  prédit maintenant les valeurs d'HadHeartAttack de notre espace de test\n# On le compare aux vraies valeurs du subdataset de test\ntable(Predicted = ifelse(y_pred> optimal_threshold, 1, 0), Actual =test_data$HadHeartAttack )","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:24:35.900266Z","iopub.execute_input":"2024-04-04T16:24:35.901654Z","iopub.status.idle":"2024-04-04T16:24:35.974393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dered<-table(Predicted = ifelse(y_pred> 0.5, 1, 0), Actual =test_data$HadHeartAttack )\nsensitivity<- (dered[1,2]/(dered[1,1]+dered[1,2]))\nspecificity<- ((dered[1,2])/(dered[2,1]+dered[2,2]))\naccuracy<-(dered[1,1]+ dered[2,2])/(dered[1,1]+dered[1,2]+dered[2,1]+dered[2,2])\nprecision<- (dered[2,2]/(dered[1,2]+dered[2,2]))\nNPV<-(dered[1,1]/(dered[1,2]+dered[1,1]))\n\nprint(paste(\"The sensitivity score is: ------>>  :\", sensitivity))\nprint(paste(\"The specificity score is: ------>>  :\", specificity))\nprint(paste(\"The accuraccy score is: ------>>  :\", accuracy))\nprint(paste(\"The NPV score is: ------>>  :\", NPV))\nprint(paste(\"The precision score is: ------>>  :\", precision))","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:24:35.978648Z","iopub.execute_input":"2024-04-04T16:24:35.980135Z","iopub.status.idle":"2024-04-04T16:24:36.130359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Sensibilité :**\n\n    La sensibilité mesure la capacité du modèle à détecter les cas positifs réels.\n    Elle est calculée en divisant le nombre de vrais positifs par la somme des vrais positifs et des faux négatifs.\n\n**Spécificité :**\n\n    La spécificité mesure la capacité du modèle à détecter les cas négatifs réels.\n    Elle est calculée en divisant le nombre de vrais négatifs par la somme des vrais négatifs et des faux positifs.\n\n**Exactitude (Accuracy) :**\n\n    L'exactitude mesure la proportion de prédictions correctes parmi toutes les prédictions.\n    Elle est calculée en divisant le nombre de prédictions correctes par le nombre total de prédictions.\n\n**Valeur prédictive négative (Negative Predictive Value) :**\n\n    La valeur prédictive négative mesure la proportion de vrais négatifs parmi toutes les prédictions négatives.\n    Elle est calculée en divisant le nombre de vrais négatifs par la somme des vrais négatifs et des faux négatifs.\n    \n**Précision (Precision) :**\n\n    La précision mesure la proportion de vrais positifs parmi toutes les prédictions positives.\n    Elle est calculée en divisant le nombre de vrais positifs par la somme des vrais positifs et des faux positifs.\n\n","metadata":{}},{"cell_type":"code","source":"# Obtenez les coefficients estimés de votre modèle\ncoefficients <- coef(model)\n# Obtenez les p-values associées à chaque coefficient\np_values <- summary(model)$coefficients[, 4]\n\n# Créez un data frame pour les coefficients et les p-values\ncoef_data <- data.frame(\n  Variable = names(coefficients),\n  Coefficient = coefficients,\n  P_Value = p_values\n)\npng(\"mon_plot.png\")\n# Tracez les coefficients\nggplot(coef_data, aes(x = reorder(Variable, Coefficient), y = Coefficient, fill = P_Value < 0.05)) +\n  geom_bar(stat = \"identity\") +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  coord_flip() +\n  labs(title = \"Coefficients of Logistic Regression Model\", x = \"Variable\", y = \"Coefficient\") +\n  theme_minimal()\ndev.off()\n# Tracez les p-values significatives\nggplot(coef_data, aes(x = reorder(Variable, P_Value), y = -log10(P_Value), fill = P_Value < 0.05)) +\n  geom_bar(stat = \"identity\") +\n  geom_hline(yintercept = -log10(0.05), linetype = \"dashed\", color = \"red\") +\n  coord_flip() +\n  labs(title = \"Significant P-Values of Logistic Regression Model\", x = \"Variable\", y = \"-log10(P-Value)\") +\n  theme_minimal()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:24:36.134783Z","iopub.execute_input":"2024-04-04T16:24:36.136469Z","iopub.status.idle":"2024-04-04T16:24:36.893494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On affiche la pente (coefficients) pour chaque variable afin de voir lesquelles ont le plus d'influence sur HadHeartAttack. Les coefficients négatifs correspondent à une influence négative ( diminue le risque ) et les coefficients positifs correspondent à une influence positive ( augmente le risque ). \n\nLes 3 variables \"False\" sont les variables exclus, car leur p value est > 0.05 donc elles ne sont pas assez statistiquement significatives pour être prises en compte dans le modèle. \n\nOn affiche également les p values. ","metadata":{}},{"cell_type":"code","source":"table(Predicted = ifelse(y_pred> optimal_threshold, 1, 0), Actual =test_data$HadHeartAttack )\ncm1 <- table(Predicted = ifelse(y_pred> optimal_threshold, 1, 0), Actual =test_data$HadHeartAttack )\n\n\nfourfoldplot(cm1, color = c(\"cyan\", \"pink\"),\n             conf.level = 0, margin = 1, main = \"Confusion Matrix\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:24:36.897925Z","iopub.execute_input":"2024-04-04T16:24:36.899603Z","iopub.status.idle":"2024-04-04T16:24:37.153002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On affiche la matrice de confusion  : \n\n     Une matrice de confusion est un tableau qui résume les performances d'un modèle de classification en comparant les prédictions du modèle avec les vraies valeurs des données. Elle permet d'évaluer les erreurs de prédiction du modèle en comptant le nombre de vrais positifs, vrais négatifs, faux positifs et faux négatifs.","metadata":{}},{"cell_type":"code","source":"\n\n\n# Tracer chaque graphique individuellement\nplot(ggeffect(model, \"Sex\"))\n\n\nplot(ggeffect(model, \"PhysicalActivities\"))\n\n\nplot(ggeffect(model, \"SleepHours\"))\n\n\nplot(ggeffect(model, \"HadStroke\"))\n\n\nplot(ggeffect(model, \"HadAsthma\"))\n\n\nplot(ggeffect(model, \"HadSkinCancer\"))\n\n\nplot(ggeffect(model, \"HadDiabetes\"))\n\n\nplot(ggeffect(model, \"DifficultyWalking\"))\n\n\nplot(ggeffect(model, \"SmokerStatus\"))\n\n\nplot(ggeffect(model, \"BMI\"))\n\n\nplot(ggeffect(model, \"AlcoholDrinkers\"))\n\n\nplot(ggeffect(model, \"GeneralHealth_numerique\"))\n\n\nplot(ggeffect(model, \"AgeInf\"))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:24:37.157697Z","iopub.execute_input":"2024-04-04T16:24:37.159368Z","iopub.status.idle":"2024-04-04T16:24:57.097021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On affiche les plot ggeffect pour chaque variable : \n\n    ggeffect affiche les effets marginaux d'une variable indépendante sur la variable dépendante dans un modèle. \n    Cela permet d'avoir une preuve plus visuelle de l'influence de chaque variable sur HadHeartAttack. ","metadata":{}},{"cell_type":"markdown","source":"### Deuxième modèle étudié: Décision Tree\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T09:25:34.443405Z","iopub.execute_input":"2024-04-02T09:25:34.445955Z","iopub.status.idle":"2024-04-02T09:25:34.596897Z"}}},{"cell_type":"markdown","source":"On décide d'effectuer l'étude sur plusieurs datasets différents pour évaluer l'impact de différents paramètres sur nos résultats. \nL'étude de l'influence de chaque variable sur le résultat étant assez complexe avec un decision tree, nous avons décidé de créer plusieurs decision tree. Un premier contenant toutes les variables ( qui servira de comparaison avec la régression logistique et la partie suivante ) et d'autres decision tree auxquels on retire une variable différente à chaque fois. L'idée étant de voir comment cela influe le résultat et donc de déterminer l'influence des variables. ","metadata":{}},{"cell_type":"code","source":"# On crée les dataset d'entraînements et de test\n\ntrain_databis <- subset(train_data, select = -c(PhysicalActivities,DifficultyWalking,SmokerStatus,AlcoholDrinkers))\nnum_copies <- 10\n\n# Création des copies avec des noms numérotés\nfor (i in 2:num_copies) {\n  assign(paste0(\"train_data\", i), train_databis)\n}\n\ntest_databis <- subset(test_data, select = -c(PhysicalActivities,DifficultyWalking,SmokerStatus,AlcoholDrinkers))\n\n\n# Création des copies avec des noms numérotés\nfor (i in 2:num_copies) {\n  assign(paste0(\"test_data\", i), test_databis)\n}\n\ntrain_data2 <- subset(train_data2, select = -c(Sex))\ntrain_data3 <- subset(train_data3, select = -c(SleepHours))\ntrain_data4 <- subset(train_data4, select = -c(HadStroke))\ntrain_data5 <- subset(train_data5, select = -c(HadAsthma))\ntrain_data6 <- subset(train_data6, select = -c(HadSkinCancer))\ntrain_data7 <- subset(train_data7, select = -c(HadDiabetes))\ntrain_data8 <- subset(train_data8, select = -c(BMI))\ntrain_data9 <- subset(train_data9, select = -c(GeneralHealth_numerique))\ntrain_data10 <- subset(train_data10, select = -c(AgeInf))\n\ntest_data2 <- subset(test_data2, select = -c(Sex))\ntest_data3 <- subset(test_data3, select = -c(SleepHours))\ntest_data4 <- subset(test_data4, select = -c(HadStroke))\ntest_data5 <- subset(test_data5, select = -c(HadAsthma))\ntest_data6 <- subset(test_data6, select = -c(HadSkinCancer))\ntest_data7 <- subset(test_data7, select = -c(HadDiabetes))\ntest_data8 <- subset(test_data8, select = -c(BMI))\ntest_data9 <- subset(test_data9, select = -c(GeneralHealth_numerique))\ntest_data10 <- subset(test_data10, select = -c(AgeInf))","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:24:57.099977Z","iopub.execute_input":"2024-04-04T16:24:57.101474Z","iopub.status.idle":"2024-04-04T16:24:57.379027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#decision trees\ndecision_tree2 <- ctree(HadHeartAttack ~ ., data = train_data2)\ndecision_tree3 <- ctree(HadHeartAttack ~ ., data = train_data3)\ndecision_tree4 <- ctree(HadHeartAttack ~ ., data = train_data4)\ndecision_tree5 <- ctree(HadHeartAttack ~ ., data = train_data5)\ndecision_tree6 <- ctree(HadHeartAttack ~ ., data = train_data6)\ndecision_tree7 <- ctree(HadHeartAttack ~ ., data = train_data7)\ndecision_tree8 <- ctree(HadHeartAttack ~ ., data = train_data8)\ndecision_tree9 <- ctree(HadHeartAttack ~ ., data = train_data9)\ndecision_tree10 <- ctree(HadHeartAttack ~ ., data = train_data10)\ndecision_tree11<- ctree(HadHeartAttack ~ ., data = train_databis)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:24:57.382050Z","iopub.execute_input":"2024-04-04T16:24:57.383649Z","iopub.status.idle":"2024-04-04T16:25:33.742552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Utiliser le modèle pour prédire les résultats sur les données de test\npredictions1 <- predict(decision_tree2, newdata = test_data2, type = \"response\")\npredictions2 <- predict(decision_tree3, newdata = test_data3, type = \"response\")\npredictions3 <- predict(decision_tree4, newdata = test_data4, type = \"response\")\npredictions4 <- predict(decision_tree5, newdata = test_data5, type = \"response\")\npredictions5 <- predict(decision_tree6, newdata = test_data6, type = \"response\")\npredictions6 <- predict(decision_tree7, newdata = test_data7, type = \"response\")\npredictions7 <- predict(decision_tree8, newdata = test_data8, type = \"response\")\npredictions8 <- predict(decision_tree9, newdata = test_data9, type = \"response\")\npredictions9 <- predict(decision_tree10, newdata = test_data10, type = \"response\")\npredictions10 <- predict(decision_tree11, newdata = test_databis, type = \"response\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:25:33.745775Z","iopub.execute_input":"2024-04-04T16:25:33.747447Z","iopub.status.idle":"2024-04-04T16:25:35.010182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Trouver le seuil qui minimise la GBE\n  # Calculer la GBE pour chaque seuil\n# Trouver le seuil qui minimise la GBE\n  # Calculer la GBE pour chaque seuil\nGBEs1 <- sapply(thresholds, function(threshold) calculate_GDE(threshold,predictions1,test_data2))\noptimal_threshold1 <- thresholds[which.min(GBEs1)]\nmin_GDE1 <- min(GBEs1)\nGBEs2 <- sapply(thresholds, function(threshold) calculate_GDE(threshold,predictions2,test_data3))\noptimal_threshold2 <- thresholds[which.min(GBEs2)]\nmin_GDE2 <- min(GBEs2)\nGBEs3 <- sapply(thresholds, function(threshold) calculate_GDE(threshold,predictions3,test_data4))\noptimal_threshold3 <- thresholds[which.min(GBEs3)]\nmin_GDE3 <- min(GBEs3)\nGBEs4 <- sapply(thresholds, function(threshold) calculate_GDE(threshold,predictions4,test_data5))\noptimal_threshold4 <- thresholds[which.min(GBEs4)]\nmin_GDE4 <- min(GBEs4)          \nGBEs5 <- sapply(thresholds, function(threshold) calculate_GDE(threshold,predictions5,test_data6))\noptimal_threshold5 <- thresholds[which.min(GBEs5)]\nmin_GDE5 <- min(GBEs5)      \nGBEs6 <- sapply(thresholds, function(threshold) calculate_GDE(threshold,predictions6,test_data7))\noptimal_threshold6 <- thresholds[which.min(GBEs6)]\nmin_GDE6 <- min(GBEs6)     \nGBEs7 <- sapply(thresholds, function(threshold) calculate_GDE(threshold,predictions7,test_data8))\noptimal_threshold7 <- thresholds[which.min(GBEs7)]\nmin_GDE7 <- min(GBEs7)      \nGBEs8 <- sapply(thresholds, function(threshold) calculate_GDE(threshold,predictions8,test_data9))\noptimal_threshold8 <- thresholds[which.min(GBEs8)]\nmin_GDE8 <- min(GBEs8)  \nGBEs9 <- sapply(thresholds, function(threshold) calculate_GDE(threshold,predictions9,test_data10))\noptimal_threshold9 <- thresholds[which.min(GBEs9)]\nmin_GDE9 <- min(GBEs9)      \nGBEs10 <- sapply(thresholds, function(threshold) calculate_GDE(threshold,predictions10,test_databis))\noptimal_threshold10 <- thresholds[which.min(GBEs10)]\nmin_GDE10 <- min(GBEs10)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:25:35.013160Z","iopub.execute_input":"2024-04-04T16:25:35.014696Z","iopub.status.idle":"2024-04-04T16:25:57.917454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n #Afficher le seuil optimal et la GBE minimale\ncat(\"Seuil optimal 1:\", optimal_threshold1, \"\\n\")\ncat(\"GBE minimale 1:\", min_GDE1, \"\\n\")\ncat(\"\\n\")\ncat(\"Seuil optimal 2:\", optimal_threshold2, \"\\n\")\ncat(\"GBE minimale 2:\", min_GDE2, \"\\n\")\ncat(\"\\n\")\ncat(\"Seuil optimal 3:\", optimal_threshold3, \"\\n\")\ncat(\"GBE minimale 3:\", min_GDE3, \"\\n\")\ncat(\"\\n\")\ncat(\"Seuil optimal 4:\", optimal_threshold4, \"\\n\")\ncat(\"GBE minimale 4:\", min_GDE4, \"\\n\")\ncat(\"\\n\")\ncat(\"Seuil optimal 5:\", optimal_threshold5, \"\\n\")\ncat(\"GBE minimale 5:\", min_GDE5, \"\\n\")\ncat(\"\\n\")\n\n#Afficher le seuil optimal et la GBE minimale\ncat(\"Seuil optimal 6:\", optimal_threshold6, \"\\n\")\ncat(\"GBE minimale 6:\", min_GDE6, \"\\n\")\ncat(\"\\n\")\ncat(\"Seuil optimal 7:\", optimal_threshold7, \"\\n\")\ncat(\"GBE minimale 7:\", min_GDE7, \"\\n\")\ncat(\"\\n\")\ncat(\"Seuil optimal 8:\", optimal_threshold8, \"\\n\")\ncat(\"GBE minimale 8:\", min_GDE8, \"\\n\")\ncat(\"\\n\")\ncat(\"Seuil optimal 9:\", optimal_threshold9, \"\\n\")\ncat(\"GBE minimale 9:\", min_GDE9, \"\\n\")\ncat(\"\\n\")\ncat(\"Seuil optimal 10:\",optimal_threshold10, \"\\n\")\ncat(\"GBE minimale 10:\", min_GDE10, \"\\n\")\ncat(\"\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:25:57.920524Z","iopub.execute_input":"2024-04-04T16:25:57.922049Z","iopub.status.idle":"2024-04-04T16:25:58.044504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Nombre de prédictions\nnum_predictions <- 10\n\n# Boucle pour traiter chaque prédiction\nfor (i in 1:num_predictions) {\n  current_prediction <- get(paste0(\"predictions\", i))  # Sélectionner la prédiction actuelle\n  \n  # Modifier la prédiction actuelle en fonction de la condition\n  for (j in 1:length(current_prediction)) {\n    if (current_prediction[j] <get(paste0(\"optimal_threshold\", i))) {\n      current_prediction[j] <- 0\n    } else {\n      current_prediction[j] <- 1\n    }\n  }\n  \n  # Mettre à jour la prédiction dans l'environnement\n  assign(paste0(\"predictions\", i), current_prediction)\n}","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:25:58.047343Z","iopub.execute_input":"2024-04-04T16:25:58.048804Z","iopub.status.idle":"2024-04-04T16:26:04.680143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Accuracies : \")\naccuracy1 <- mean(predictions1 == test_data2$HadHeartAttack)\ncat(\"Exactitude du modèle sur les données de test:\", accuracy1, \"\\n\")\naccuracy2 <- mean(predictions2 == test_data3$HadHeartAttack)\ncat(\"Exactitude du modèle sur les données de test:\", accuracy2, \"\\n\")\naccuracy3 <- mean(predictions3 == test_data4$HadHeartAttack)\ncat(\"Exactitude du modèle sur les données de test:\", accuracy3, \"\\n\")\naccuracy4 <- mean(predictions4 == test_data5$HadHeartAttack)\ncat(\"Exactitude du modèle sur les données de test:\", accuracy4, \"\\n\")\naccuracy5 <- mean(predictions5 == test_data6$HadHeartAttack)\ncat(\"Exactitude du modèle sur les données de test:\", accuracy5, \"\\n\")\naccuracy6 <- mean(predictions6 == test_data7$HadHeartAttack)\ncat(\"Exactitude du modèle sur les données de test:\", accuracy6, \"\\n\")\naccuracy7 <- mean(predictions7 == test_data8$HadHeartAttack)\ncat(\"Exactitude du modèle sur les données de test:\", accuracy7, \"\\n\")\naccuracy8 <- mean(predictions8 == test_data9$HadHeartAttack)\ncat(\"Exactitude du modèle sur les données de test:\", accuracy8, \"\\n\")\naccuracy9 <- mean(predictions9 == test_data10$HadHeartAttack)\ncat(\"Exactitude du modèle sur les données de test:\", accuracy9, \"\\n\")\naccuracy10 <- mean(predictions10 == test_databis$HadHeartAttack)\ncat(\"Exactitude du modèle sur les données de test:\", accuracy10, \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:26:04.683022Z","iopub.execute_input":"2024-04-04T16:26:04.684551Z","iopub.status.idle":"2024-04-04T16:26:04.763855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On observe ici les différences d'exactitude pour chaque variable.","metadata":{}},{"cell_type":"code","source":"# Créer la table de contingence\n  table_results <- table(Predicted = ifelse(predictions10 > optimal_threshold10, 1, 0),\n                         Actual = test_databis$HadHeartAttack)\n  \n\n  \n  # Afficher la matrice de confusion\n  fourfoldplot(table_results, color = c(\"cyan\", \"pink\"),\n               conf.level = 0, margin = 1)\n# Définir le nombre de prédictions\nnum_predictions <- 9\n\n# Créer un mfrow pour afficher les graphiques\npar(mfrow = c(2, 5))\n\n# Boucle sur les prédictions\nfor (i in 1:num_predictions) {\n  current_prediction <- get(paste0(\"predictions\", i))\n  \n\n  \n  # Créer la table de contingence\n  table_results <- table(Predicted = ifelse(current_prediction > get(paste0(\"optimal_threshold\", i)), 1, 0),\n                         Actual = get(paste0(\"test_data\", (i+1)))$HadHeartAttack)\n  \n\n  \n  # Afficher la matrice de confusion\n  fourfoldplot(table_results, color = c(\"cyan\", \"pink\"),\n               conf.level = 0, margin = 1)\n  \n\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:26:04.767356Z","iopub.execute_input":"2024-04-04T16:26:04.768729Z","iopub.status.idle":"2024-04-04T16:26:05.629487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On crée les matrices de confusion pour chaque cas. ","metadata":{}},{"cell_type":"code","source":"dered<-table(Predicted = ifelse(predictions10> optimal_threshold10, 1, 0), Actual =test_databis$HadHeartAttack )\nsensitivity<- (dered[1,2]/(dered[1,1]+dered[1,2]))\nspecificity<- ((dered[1,2])/(dered[2,1]+dered[2,2]))\naccuracy<-(dered[1,1]+ dered[2,2])/(dered[1,1]+dered[1,2]+dered[2,1]+dered[2,2])\nprecision<- (dered[2,2]/(dered[1,2]+dered[2,2]))\nNPV<-(dered[1,1]/(dered[1,2]+dered[1,1]))\n\nprint(paste(\"The sensitivity score is: ------>>  :\", sensitivity))\nprint(paste(\"The specificity score is: ------>>  :\", specificity))\nprint(paste(\"The accuraccy score is: ------>>  :\", accuracy))\nprint(paste(\"The NPV score is: ------>>  :\", NPV))\nprint(paste(\"The precision score is: ------>>  :\", precision))","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:26:05.634013Z","iopub.execute_input":"2024-04-04T16:26:05.635561Z","iopub.status.idle":"2024-04-04T16:26:05.786472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On calcule la sensitivity, specificity, accuracy, precision et NPV pour le cas avec toutes les variables. ","metadata":{}},{"cell_type":"markdown","source":"### **Random forest**\n\nNous avons choisi de faire une random forest car elle utilise les arbres de décision, elle permet d'améliorer la précision obtenu avec le decision tree car elle en utilise plusieurs. ","metadata":{}},{"cell_type":"markdown","source":"Par soucis technique, nous devons réduire la taille de l'échantillon choisi, sinon le code est trpo long à l'exéution. ","metadata":{}},{"cell_type":"code","source":"data2<-data[1:650,]\n\nhead(data2)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:26:05.789142Z","iopub.execute_input":"2024-04-04T16:26:05.790608Z","iopub.status.idle":"2024-04-04T16:26:05.827165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creation d'espace d'entrainement et de test\n#Creation d'espace d'entrainement et de test\n set.seed(123)\n rftrain_index <- sample(nrow(data2), floor(0.8*nrow(data2)), replace = FALSE)\n rftrain_data <- data[rftrain_index, ]\n rftest_data <- data[-rftrain_index, ]","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:26:05.829958Z","iopub.execute_input":"2024-04-04T16:26:05.831513Z","iopub.status.idle":"2024-04-04T16:26:05.882339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set.seed(123)\nml_rf = randomForest(formula = HadHeartAttack ~ ., \n                         data =rftrain_data,\n                         mtry = sqrt(ncol(rftrain_data)-1), # minus the response\n                         importance = T, # to estimate predictors importance\n                         ntree = 500) # 500 by default\nml_rf\n#As before we plot the measure for the importance of the regressors:\nvarImpPlot(ml_rf)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:26:05.885359Z","iopub.execute_input":"2024-04-04T16:26:05.886928Z","iopub.status.idle":"2024-04-04T16:26:06.726420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On affiche le résultat de la random forest et on affiche varImpPlot qui plot l'importance des variables mesurée par la diminution de l'erreur de prédiction lorsqu'une variable est incluse dans les arbres de la forêt. ","metadata":{}},{"cell_type":"code","source":"predrf <- predict(ml_rf, newdata = rftest_data, type = \"response\")","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:26:06.729705Z","iopub.execute_input":"2024-04-04T16:26:06.731460Z","iopub.status.idle":"2024-04-04T16:26:18.485999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GBEsrf <- sapply(thresholds, function(threshold) calculate_GDE(threshold,predrf,rftest_data))\noptimal_thresholdrf <- thresholds[which.min(GBEsrf)]\nmin_GDErf <- min(GBEsrf)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:26:18.488973Z","iopub.execute_input":"2024-04-04T16:26:18.490409Z","iopub.status.idle":"2024-04-04T16:26:39.545225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat(\"Seuil optimal rf:\",optimal_thresholdrf, \"\\n\")\ncat(\"GBE minimale rf:\", min_GDErf, \"\\n\")\ncat(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:26:39.548561Z","iopub.execute_input":"2024-04-04T16:26:39.550270Z","iopub.status.idle":"2024-04-04T16:26:39.572358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table(Predicted = ifelse(predrf> optimal_thresholdrf, 1, 0), Actual =rftest_data$HadHeartAttack )\ncm1 <- table(Predicted = ifelse(predrf> optimal_thresholdrf, 1, 0), Actual =rftest_data$HadHeartAttack )\n\n\nfourfoldplot(cm1, color = c(\"cyan\", \"pink\"),\n             conf.level = 0, margin = 1, main = \"Confusion Matrix\")","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:26:39.575121Z","iopub.execute_input":"2024-04-04T16:26:39.576712Z","iopub.status.idle":"2024-04-04T16:26:40.289061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On peut voir ici les limites du Bayes Test et de la minimisation du GDE. Ici la meilleure solution au sens de Bayes nous donne un seuil  pour le  modèle qui ne prédit que des valeurs nulles et qui est donc obsolète.","metadata":{"execution":{"iopub.status.busy":"2024-04-01T21:32:33.016948Z","iopub.execute_input":"2024-04-01T21:32:33.018740Z","iopub.status.idle":"2024-04-01T21:32:33.382166Z"}}},{"cell_type":"code","source":"table(Predicted = ifelse(predrf> 0.2, 1, 0), Actual =rftest_data$HadHeartAttack )\ncm1 <- table(Predicted = ifelse(predrf> 0.2, 1, 0), Actual =rftest_data$HadHeartAttack )\n\n\nfourfoldplot(cm1, color = c(\"cyan\", \"pink\"),\n             conf.level = 0, margin = 1, main = \"Confusion Matrix\")","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:26:40.292095Z","iopub.execute_input":"2024-04-04T16:26:40.293677Z","iopub.status.idle":"2024-04-04T16:26:41.029242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dered<-table(Predicted = ifelse(predrf> 0.5, 1, 0), Actual =rftest_data$HadHeartAttack )\nsensitivity<- (dered[1,2]/(dered[1,1]+dered[1,2]))\nspecificity<- ((dered[1,2])/(dered[2,1]+dered[2,2]))\naccuracy<-(dered[1,1]+ dered[2,2])/(dered[1,1]+dered[1,2]+dered[2,1]+dered[2,2])\nprecision<- (dered[2,2]/(dered[1,2]+dered[2,2]))\nNPV<-(dered[1,1]/(dered[1,2]+dered[1,1]))\n\nprint(paste(\"The sensitivity score is: ------>>  :\", sensitivity))\nprint(paste(\"The specificity score is: ------>>  :\", specificity))\nprint(paste(\"The accuraccy score is: ------>>  :\", accuracy))\nprint(paste(\"The NPV score is: ------>>  :\", NPV))\nprint(paste(\"The precision score is: ------>>  :\", precision))","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:26:41.031983Z","iopub.execute_input":"2024-04-04T16:26:41.033528Z","iopub.status.idle":"2024-04-04T16:26:41.367742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cross validation \n\nLa Cross Validation est une méthode de rééchantillonnage statistique utilisée pour évaluer les performances du modèle d'apprentissage automatique sur des données qu'il ne voit pas aussi objectivement et précisément que possible.","metadata":{}},{"cell_type":"markdown","source":"Ici nous effectuons une méthode K-Fold qui appliquent différentes étapes.\n\nElle divise l'espace d'entrainement en n_fold sous6dataset.\nDans notre cas , on prendra n_fold=9.\n\nOn nomme ensuite un sous data_set de validation , les huits autres serviront d'entrainement. On établit alors le modèle avec ces dernieres huits parties et on l'évalue avec le sous-dataset de validation. On calcule alors l'accuracy.\n\nOn procède de même en nommant un par un les divers sous_datasets en jeu de validation. \n\nOn enregistre à chaque pas l'accuracy pour pouvoir comparer a la fin ","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Cross Validation\n\nctrl <- trainControl(method = \"cv\", number = 9 )  # k = 9, vous pouvez choisir un autre nombre selon vos besoins\nctrl","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:26:41.370526Z","iopub.execute_input":"2024-04-04T16:26:41.371945Z","iopub.status.idle":"2024-04-04T16:26:41.402840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Cross validation pour la régression\n\nPoue effectuer une classification et ainsi obtenir une accuracy, on est forcé de transformé notre variable de réponse HadHeartAttack en factor. Il en sera de même pour les autres modèles ","metadata":{}},{"cell_type":"code","source":"train_data$HadHeartAttack <-factor(train_data$HadHeartAttack, levels = c(0, 1))\nresults <- train(HadHeartAttack ~ ., data = train_data, method = \"glm\", trControl = ctrl,metric= \"Accuracy\")  # Remplacez \"target\" par le nom de votre variable cible\nprint(results)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:26:41.405793Z","iopub.execute_input":"2024-04-04T16:26:41.407275Z","iopub.status.idle":"2024-04-04T16:27:13.597172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Cross Validation pour Random Forest","metadata":{}},{"cell_type":"code","source":"rftrain_data$HadHeartAttack <-factor(rftrain_data$HadHeartAttack, levels = c(0, 1))\nresults3 <- train(HadHeartAttack ~ ., data = rftrain_data, method = \"rf\", trControl = ctrl,metric= \"Accuracy\")  # Remplacez \"target\" par le nom de votre variable cible\nprint(results3)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:27:13.601677Z","iopub.execute_input":"2024-04-04T16:27:13.604560Z","iopub.status.idle":"2024-04-04T16:27:22.248989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Cross Validation pour décision tree","metadata":{}},{"cell_type":"code","source":"train_databis$HadHeartAttack <-factor(train_databis$HadHeartAttack, levels = c(0, 1))\nresults2 <- train(HadHeartAttack ~ ., data = train_databis, method = \"ctree\", trControl = ctrl,metric= \"Accuracy\")  # Remplacez \"target\" par le nom de votre variable cible\nprint(results2)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:27:22.253158Z","iopub.execute_input":"2024-04-04T16:27:22.254630Z","iopub.status.idle":"2024-04-04T16:35:32.057486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On remarque que l'accuracy calculé du random forest a diminué par rapport au calcul précédemment effectué (87<94). Cela est surement la conséquence d'un suraprentissage du modèle.","metadata":{}},{"cell_type":"code","source":"rftrain_data$HadHeartAttack <-as.integer(rftrain_data$HadHeartAttack)\ntrain_data$HadHeartAttack <-as.integer(train_data$HadHeartAttack)\ntrain_databis$HadHeartAttack <-as.integer(train_databis$HadHeartAttack)\nrftest_data$HadHeartAttack <-as.integer(rftest_data$HadHeartAttack)\ndata$HadHeartAttack <-as.integer(data$HadHeartAttack)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T16:35:32.061495Z","iopub.execute_input":"2024-04-04T16:35:32.063022Z","iopub.status.idle":"2024-04-04T16:35:32.084570Z"},"trusted":true},"execution_count":null,"outputs":[]}]}